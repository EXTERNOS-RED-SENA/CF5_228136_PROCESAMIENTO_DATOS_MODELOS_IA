{"remainingRequest":"/home/runner/work/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/node_modules/thread-loader/dist/cjs.js!/home/runner/work/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/node_modules/babel-loader/lib/index.js!/home/runner/work/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/node_modules/cache-loader/dist/cjs.js??ref--1-0!/home/runner/work/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/node_modules/vue-loader/lib/index.js??vue-loader-options!/home/runner/work/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/src/views/Tema3.vue?vue&type=script&lang=js","dependencies":[{"path":"/home/runner/work/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/src/views/Tema3.vue","mtime":1732499125042},{"path":"/home/runner/work/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/babel.config.js","mtime":1732499124882},{"path":"/home/runner/work/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/home/runner/work/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/node_modules/thread-loader/dist/cjs.js","mtime":499162500000},{"path":"/home/runner/work/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/node_modules/babel-loader/lib/index.js","mtime":456789000000},{"path":"/home/runner/work/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/home/runner/work/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/CF5_228136_PROCESAMIENTO_DATOS_MODELOS_IA/node_modules/vue-loader/lib/index.js","mtime":499162500000}],"contextDependencies":[],"result":[{"type":"Buffer","data":"base64:aW1wb3J0IEFjb3JkaW9uQSBmcm9tICcuLi9ib290c3RyYXAvQWNvcmRpb25BJzsKZXhwb3J0IGRlZmF1bHQgewogIG5hbWU6ICdUZW1hMycsCiAgY29tcG9uZW50czogewogICAgQWNvcmRpb25BCiAgfSwKICBkYXRhOiAoKSA9PiAoewogICAgLy8gdmFyaWFibGVzIGRlIHZ1ZQogIH0pLAogIG1vdW50ZWQoKSB7CiAgICB0aGlzLiRuZXh0VGljaygoKSA9PiB7CiAgICAgIHRoaXMuJGFvc1JlZnJlc2goKTsKICAgIH0pOwogIH0sCiAgdXBkYXRlZCgpIHsKICAgIHRoaXMuJGFvc1JlZnJlc2goKTsKICB9Cn07"},{"version":3,"names":["AcordionA","name","components","data","mounted","$nextTick","$aosRefresh","updated"],"sources":["src/views/Tema3.vue"],"sourcesContent":["<template lang=\"pug\">\n.curso-main-container.pb-3\n  BannerInterno\n  .container.tarjeta.tarjeta--blanca.p-4.p-md-5.mb-5\n    .titulo-principal.color-acento-contenido\n      .titulo-principal__numero\n        span 3\n      h1 Segmentación de datos\n\n    .row.justify-content-center.bg9.mb-5\n      .col-lg-7.p-0.my-lg-0.my-3.j1\n        .p-4\n          p.mb-0 La segmentación de datos es un paso clave en el proceso de preparación de #[i Datasets] para el aprendizaje automático. Dividir los datos en diferentes subconjuntos permite evaluar el rendimiento del modelo de manera efectiva y garantizar su capacidad para generalizar a datos no vistos. En este capítulo, se abordarán los conceptos de conjuntos de entrenamiento, prueba y validación, la importancia de la validación cruzada, y las estrategias de muestreo que aseguran una adecuada distribución de los datos..\n      .col-lg-5.p-0.my-lg-0.my-3.j1\n        img.img-mov(src='@/assets/curso/temas/30.png') \n\n    Separador \n    #t_3_1.titulo-segundo.color-acento-contenido\n      h2 3.1 Conjuntos de entrenamiento y prueba\n    p La correcta división del #[i Dataset] en conjuntos de entrenamiento y prueba es esencial para evaluar adecuadamente el rendimiento del modelo de #[i machine learning]. En general, el #[i Dataset] se divide en dos o más subconjuntos:        \n\n    .row.bg7.align-items-center\n      .px-lg-5.px-4  \n        .row.justify-content-center.text-center.mb-5\n          .col-lg-4.my-lg-0.my-3\n            .bg10.brad1.p-4.h-100\n              img.img-t.img-a.mb-4(src='@/assets/curso/temas/33.png' alt='')\n              .row.justify-content-center.mb-3\n                .col-auto.bg11.px-3.py-1                        \n                  h5.mb-0.text-center Conjunto de Entrenamiento\n              p.mb-0 Es la porción del #[i Dataset] que se utiliza para entrenar el modelo. El objetivo es proporcionar al modelo suficientes ejemplos para aprender patrones relevantes y generalizables.\n          .col-lg-4.my-lg-0.my-3\n            .bg5.brad1.p-4.h-100\n              img.img-t.img-a.mb-4(src='@/assets/curso/temas/34.png' alt='')\n              .row.justify-content-center.mb-3\n                .col-auto.bg11.px-3.py-1                        \n                  h5.mb-0.text-center Conjunto de Prueba\n              p.mb-0 Este conjunto se mantiene separado del proceso de entrenamiento y se utiliza para evaluar la capacidad del modelo para generalizar a nuevos datos. El conjunto de prueba permite medir el rendimiento real del modelo y evitar el sobreajuste.\n\n          .col-lg-4.my-lg-0.my-3\n            img.img-t.img-a.mb-4(src='@/assets/curso/temas/31.png' alt='')        \n\n        .row.justify-content-center.mb-5\n          .col-lg-4.my-lg-0.my-3.j1\n            img.img-t.img-a(src='@/assets/curso/temas/32.png')              \n          .col-lg-8.my-lg-0.my-3\n            p Una buena práctica es destinar aproximadamente un 70-80% de los datos para el entrenamiento y el 20-30% restante para la prueba. Sin embargo, estas proporciones pueden ajustarse según el tamaño del #[i Dataset] y la naturaleza del problema.\n\n            .row.justify-content-center.align-items-center.bg12.brad1.p-4.mb-4\n              .col-lg-auto\n                img.img-a.img-t(src='@/assets/curso/temas/19.png' alt='')\n              .col.pt-lg-0.pt-md-4\n                p.mb-0 Es importante asegurarse de que tanto el conjunto de entrenamiento como el conjunto de prueba sean representativos de la población de datos, evitando así que el modelo aprenda patrones específicos del conjunto de entrenamiento que no se replican en el conjunto de prueba. \n\n            p La división de datos en conjuntos de entrenamiento y prueba representa el primer paso en la evaluación sistemática de modelos de #[i machine learning]. Esta separación permite simular cómo se comportará el modelo ante datos que nunca ha visto, proporcionando una estimación más realista de su rendimiento en el mundo real. Para comprender mejor las implicaciones de diferentes estrategias de división de datos, consideremos las siguientes proporciones comúnmente utilizadas y sus casos de uso:\n\n        .row.justify-content-center.mb-5\n          .col-lg-10\n            .titulo-sexto.color-acento-botones\n              h5 Tabla 3. \n              span Proporciones empleadas en entrenamiento y pruebas\n\n            .tabla-a.color-acento-botones.text-center\n              table\n                caption Fuente: OIT, 2024.\n                thead\n                  tr\n                    th Estrategia de división\n                    th Proporción (Train/Test)\n                    th Casos de uso\n                    th Consideraciones especiales\n\n                tbody\n                  tr\n                    td Clásica\n                    td 80/20\n                    td #[i Datasets] grandes (>10,000 muestras)\n                    td Balance entre representatividad y evaluación\n                  tr\n                    td Conservadora\n                    td 90/10\n                    td #[i Datasets] muy grandes (>100,000 muestras)\n                    td Maximiza datos de entrenamiento\n                  tr\n                    td Equilibrada\n                    td 70/30\n                    td #[i Datasets] medianos (1,000-10,000 muestras)\n                    td Mayor confianza en la evaluación\n                  tr\n                    td Proporcional\n                    td 60/40\n                    td #[i Datasets] pequeños (<1,000 muestras)\n                    td Evita sobreajuste en muestras limitadas\n                  tr\n                    td Específica del dominio\n                    td Variable\n                    td Casos con restricciones temporales o secuenciales\n                    td Respeta la estructura temporal de los datos \n\n\n    .row.justify-content-center\n      .col-lg-10\n        .bg9.p-4.brad\n          p.mb-0 La elección de la proporción adecuada depende no solo del tamaño del #[i Dataset], sino también de factores como la complejidad del problema, la variabilidad en los datos y los requisitos específicos del proyecto. En algunos casos, puede ser necesario ajustar estas proporciones para garantizar que ambos conjuntos contengan muestras representativas de todas las clases o categorías importantes.\n\n    Separador \n    #t_3_2.titulo-segundo.color-acento-contenido\n      h2 3.2 Validación cruzada \n\n    .bloque-texto-g.color-secundario.p-3.p-sm-4.p-md-5.mb-5\n      .bloque-texto-g__img(\n        :style=\"{'background-image': `url(${require('@/assets/curso/temas/37.png')})`}\"\n      )\n      .bloque-texto-g__texto.p-4\n        p.mb-0 La validación cruzada es una técnica que se utiliza para evaluar el rendimiento de un modelo de aprendizaje automático de manera más robusta. Consiste en dividir el #[i Dataset] en múltiples subconjuntos o \"folds\" y entrenar el modelo varias veces, cada vez utilizando uno de los subconjuntos como conjunto de prueba y los demás como conjunto de entrenamiento.\n\n    .row.justify-content-center.text-center.mb-5\n      .col-lg-5.my-lg-0.my-3\n        .bg5.brad1.p-4.h-100\n          img.img-t.img-a.mb-4(src='@/assets/curso/temas/38.png' alt='')\n          .row.justify-content-center.mb-3\n            .col-auto.bg11.px-3.py-1                        \n              h5.mb-0.text-center.fst-italic K-Fold Cross-Validation\n          p.mb-0 Esta es una de las formas más comunes de validación cruzada. El #[i Dataset] se divide en \"k\" partes (folds) y se entrena el modelo \"k\" veces, cada vez utilizando un fold diferente como conjunto de prueba y los restantes como conjunto de entrenamiento. El rendimiento se promedia sobre todas las iteraciones, proporcionando una medida más precisa de la capacidad del modelo para generalizar.\n      .col-lg-5.my-lg-0.my-3\n        .bg5.brad1.p-4.h-100\n          img.img-t.img-a.mb-4(src='@/assets/curso/temas/39.png' alt='')\n          .row.justify-content-center.mb-3\n            .col-auto.bg11.px-3.py-1                        \n              h5.mb-0.text-center.fst-italic Leave-One-Out Cross-Validation (LOOCV)\n          p.mb-0 En este enfoque, cada observación del #[i Dataset] se utiliza una vez como conjunto de prueba, mientras que el resto se utiliza para el entrenamiento. Aunque es una técnica muy precisa, puede ser computacionalmente costosa para #[i Datasets] grandes. \n\n    .row.justify-content-center\n      .col-lg-10\n        .bg9.p-4.brad\n          p.mb-0 La validación cruzada permite reducir la varianza en la estimación del rendimiento del modelo y asegurar que se está utilizando toda la información disponible en el #[i Dataset] de manera eficiente. Esto es especialmente útil cuando se trabaja con #[i Datasets] de tamaño limitado.\n\n    Separador \n    #t_3_3.titulo-segundo.color-acento-contenido\n      h2 3.3 Estrategias de muestreo \n\n    p Las estrategias de muestreo son fundamentales para garantizar que los conjuntos de entrenamiento, prueba y validación sean representativos de la población general. Algunas de las estrategias más comunes incluyen:\n\n    .row.justify-content-center.mb-4 \n      .col-lg-4.my-3\n        img.img-a.img-t(src='@/assets/curso/temas/40.png', alt='')                \n      .col-lg-8.my-3\n        AcordionA(tipo=\"a\" clase-tarjeta=\"tarjeta bg8\")\n          div(titulo=\"Muestreo Aleatorio Simple \")\n            p Cada observación tiene la misma probabilidad de ser seleccionada. Esta es la técnica más básica y es adecuada cuando el #[i Dataset] es lo suficientemente grande y no existen problemas de desequilibrio entre clases.\n          div(titulo=\"Muestreo Estratificado \")\n            p Se asegura de que la distribución de clases o categorías en los subconjuntos sea similar a la del #[i Dataset] original. Esto es especialmente importante cuando se trabaja con #[i Datasets] desbalanceados, ya que garantiza que todas las clases estén representadas adecuadamente en cada subconjunto.\n          div(titulo=\"Muestreo con Reemplazo \")\n            p En este tipo de muestreo, una observación seleccionada se devuelve al #[i Dataset] y puede ser seleccionada nuevamente. Aunque no es muy común en la segmentación de #[i Datasets] para #[i machine learning], puede ser útil en ciertos enfoques como el #[i bootstrap].                        \n\n    p A continuación, se presenta una tabla que resume las principales estrategias de muestreo y sus características:\n\n    .row.justify-content-center.mb-5\n      .col-lg-10\n        .titulo-sexto.color-acento-botones\n          h5 Tabla 4. \n          span Estrategias de muestreo\n\n        .tabla-a.color-acento-botones.text-center\n          table\n            caption Fuente: OIT, 2024.\n            thead\n              tr\n                th Estrategia de Muestreo\n                th Descripción\n                th Ventajas\n                th Desventajas\n\n            tbody\n              tr\n                td Muestreo aleatorio simple\n                td Cada observación tiene la misma probabilidad de ser seleccionada\n                td Fácil de implementar y comprender\n                td No garantiza representatividad en #[i Datasets] desbalanceados\n              tr\n                td Muestreo estratificado \n                td Asegura que la distribución de clases sea similar en cada subconjunto\n                td Útil para #[i Datasets] desbalanceados\n                td Puede ser complejo de implementar\n              tr\n                td Muestreo con reemplazo\n                td Las observaciones seleccionadas se devuelven al #[i Dataset]\n                td Útil para enfoques de #[i bootstrap]\n                td Puede introducir duplicados innecesarios\n\n    .row.justify-content-center\n      .col-lg-7.my-lg-0.my-3\n        p Estas estrategias permiten asegurar una correcta división del #[i Dataset] y garantizar que los modelos entrenados tengan una buena capacidad para generalizar a datos no vistos, evitando problemas de sobreajuste o subajuste.\n        .bg4.brad.p-3.j1\n          p.mb-0 Al concluir este capítulo, se debe resaltar que una segmentación adecuada de los datos es fundamental para evaluar correctamente el rendimiento de los modelos de #[i machine learning]. Dividir los datos de manera estratégica permite obtener una visión precisa de cómo se comportará el modelo en situaciones reales y garantiza que se está maximizando el valor del #[i Dataset] disponible. La validación cruzada y el uso adecuado de estrategias de muestreo son prácticas recomendadas para asegurar que los resultados obtenidos sean confiables y representativos del comportamiento esperado del modelo en producción.\n      .col-lg-5.my-lg-0.my-3.j1\n        img.img-t.img-a(src='@/assets/curso/temas/35.png')                                                                                 \n</template>\n\n<script>\nimport AcordionA from '../bootstrap/AcordionA'\nexport default {\n  name: 'Tema3',\n  components: { AcordionA },\n  data: () => ({\n    // variables de vue\n  }),\n  mounted() {\n    this.$nextTick(() => {\n      this.$aosRefresh()\n    })\n  },\n  updated() {\n    this.$aosRefresh()\n  },\n}\n</script>\n\n<style lang=\"sass\"></style>\n"],"mappings":"AAwMA,OAAAA,SAAA;AACA;EACAC,IAAA;EACAC,UAAA;IAAAF;EAAA;EACAG,IAAA,EAAAA,CAAA;IACA;EAAA,CACA;EACAC,QAAA;IACA,KAAAC,SAAA;MACA,KAAAC,WAAA;IACA;EACA;EACAC,QAAA;IACA,KAAAD,WAAA;EACA;AACA","ignoreList":[]}]}